if (runerrs[i,1]==27)  {
write_output("ERROR: One of the variables in your model is a constant.");
}
if (runerrs[i,1]==28)  {
write_output("ERROR: You did not provide a valid X variable name.");
}
if (runerrs[i,1]==29)  {
write_output("ERROR: You cannot include your X variable as a mediator.");
}
if (runerrs[i,1]==30)  {
write_output("ERROR: You cannot include your Y variable as a mediator.");
}
}
}
if (errs == 0)  {
if ((boot > 1) || (mc > 0))  {
if ((bconoff == 1) && (boot > 0))  {
write_output("Number of bootstrap samples for bias corrected bootstrap confidence intervals:")
write_output(boot, row.names=FALSE, col.names=FALSE);
}
if ((bconoff == 0) && (boot > 0))  {
write_output("Number of bootstrap samples for percentile bootstrap confidence intervals:")
write_output(boot, row.names=FALSE, col.names=FALSE);
}
if (mc > 1)  {
write_output("Number of samples for Monte Carlo confidence intervals:")
write_output(mc, row.names=FALSE, col.names=FALSE);
}
if (booterr == 1)  {
badend=badend[1,2:(ncol(badend)), drop=F];
badend=t(badend);
write_output("WARNING: Bootstrap CI endpoints below not trustworthy. Decrease confidence or increase bootstraps")
write_output(badend, row.names=FALSE, col.names=FALSE);
}
}
write_output("Level of confidence for all confidence intervals in output:")
write_output(conf, row.names=FALSE, col.names=FALSE);
if ((center == 1) && (ncol(centvar) > 0))  {
centvar=centvar[1,2:ncol(centvar), drop=F];
write_output("NOTE: The following variables were mean centered prior to analysis:")
write_output(centvar, row.names=FALSE, col.names=FALSE);
}
for (i in 1:notes) {
if (note[i,1]==1)  {
write_output("NOTE: Confidence level restricted to between 50 and 99.9999%.  95% confidence is provided.");
}
if (note[i,1]==2)  {
write_output("NOTE: Effect size measures not available for models with dichotomous outcomes.");
}
if (note[i,1]==3)  {
write_output("NOTE: All standard errors for continuous outcome models are based on the HC3 estimator.");
}
if (note[i,1]==6)  {
write_output("NOTE: The number of bootstrap samples was adjusted upward given your desired confidence.");
}
if (note[i,1]==7)  {
write_output("NOTE: The Johnson-Neyman method is available only for models 1 and 3.");
}
if (note[i,1]==8)  {
write_output("NOTE: The Johnson-Neyman method cannot be used with a dichotomous moderator.");
}
if (note[i,1]==9)  {
write_output("NOTE: Some bootstrap samples had to be replaced. The number of such replacements was:")
write_output(bad, row.names=FALSE, col.names=FALSE);
}
if (note[i,1]==10)  {
write_output("NOTE: Effect size measures for indirect effects not available for models with covariates.");
}
if (note[i,1]==11)  {
write_output("NOTE: Some cases were deleted due to missing data. The number of such cases was:")
write_output(nmiss, row.names=FALSE, col.names=FALSE);
}
if (note[i,1]==12)  {
write_output("NOTE: Monte Carlo method available only for models 4 and 5.  Bootstrapping was used instead.");
}
if (note[i,1]==13)  {
write_output("NOTE: The number of Monte Carlo samples was adjusted upward given your desired confidence.");
}
}
}
}
bcboot <- function(databcbt,estmte=9999, env = parent.frame()) {
temp=databcbt[order(databcbt),, drop=F]
badlo <<- 0;
badhi <<- 0;
if (estmte != 9999) {
boot=env$boot
xp2=env$xp2
p0=-.322232431088;
p1 = -1;
p2 = -.342242088547;
p3 = -.0204231210245;
p4 = -.0000453642210148;
q0 = .0993484626060;
q1 = .588581570495;
q2 = .531103462366;
q3 = .103537752850;
q4 = .0038560700634;
pv = length(temp[(temp < as.vector(estmte))]) / boot
ppv=pv;
if (pv > 0.5) ppv=1-pv
y5=sqrt(-2*log(ppv));
xp=y5+((((y5*p4+p3)*y5+p2)*y5+p1)*y5+p0)/((((y5*q4+q3)*y5+q2)*y5+q1)*y5+q0);
if (pv <= .5) xp=-xp
cilow=round(boot*(pnorm(2*xp+xp2)));
cihigh=trunc(boot*(pnorm(2*xp+(-xp2))))+1;
if (cilow < 1) {
cilow=1
booterr=1
badlo=1
}
if (cihigh > boot) {
cihigh=boot
booterr=1
badhi=1
}
return(list(temp[cilow,1, drop=F], temp[cihigh,1, drop=F]))
}
if (estmte==9999) {
cilow=env$cilow
cihigh=env$cihigh
return(list(temp[cilow,1, drop=F], temp[cihigh,1, drop=F]))
}
}
x <- 2
y <- 3
z <- complex(real = x, imaginary = y)
z
fun <- function (x) cos(2*x)^3
fun()
fun(3)
myVector <- c(1, 3, 5, 7)
load("C:/Dropbox/5277OS - Learning Scientific Computing with R/BookDataSnapshot.RData")
View(matrix1)
View(matrix1)
View(matrix2)
View(matrix2)
View(matrix3)
View(matrix3)
View(matrix2)
View(matrix2)
View(matrix3)
View(matrix3)
cbind(matrix2, matrix3)
matrix1 <- (rep(1:10), 2, 5)
matrix1 <- matrix(rep(1:10), 2, 5)
View(matrix1)
View(matrix1)
matrix5 <- matrix(rep(1:10), 2, 5)
matrix6 <- matrix(rep(11:30), 3, 5)
load("C:/Dropbox/5277OS - Learning Scientific Computing with R/BookDataSnapshot.RData")
matrix5 <- matrix(rep(1:10), 2, 5)
matrix6 <- matrix(rep(11:25), 3, 5)
View(matrix5)
View(matrix5)
View(matrix6)
View(matrix6)
matrix7 <- rbind(matrix5, matrix 6)
matrix7 <- cbind(matrix5, matrix 6)
matrix7 <- cbind(matrix5, matrix6)
matrix7 <- rbind(matrix5, matrix6)
matrix5 <- matrix(rep(1:10), 2, 5)
matrix6 <- matrix(rep(11:25), 3, 5)
matrix7 <- rbind(matrix5, matrix6)
matrix5 <- matrix(rep(1:10), 2, 5)
matrix5
matrix6 <- matrix(rep(11:25), 3, 5)
matrix6
matrix7 <- rbind(matrix5, matrix6)
matrix7
install.packages("gdata", dependencies=TRUE)
library(gdata)
dim(matrix1)
dim(matrix2)
dim(matrix3)
cbindX(matrix2)
cbindX(matrix2, matrix3)
matrix2
matrix3
matrix2
matrix3
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
train <- segmentationOriginal[segmentationOriginal$Case == "Train",]
test <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
fit <- train(Class~.,method="rpart",data=train)
print(fit)
print(fit)
plot(fit$finalModel,uniform=TRUE)
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
data.a <- data.frame(TotalIntench2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=20)
data.b <- data.frame( TotalIntench2 = 50,000, FiberWidthCh1 = 10,VarIntenCh4 = 100)
data.c <- data.frame(TotalIntench2 = 57,000, FiberWidthCh1 = 8,VarIntenCh4 = 100)
data.d <- data.frame(FiberWidthCh1 = 8,VarIntenCh4 = 100, PerimStatusCh1=2)
predict(fit,data.a)
```
data.a
predict(fit,data.a)
predict(fit,data.b)
predict(fit,data.c)
predict(fit,data.d)
library(pgmm)
install.packages("pgmm")
library(plm)
install.packages("plm")
library(plm)
library(pgmm)
data(olive)
olive = olive[,-1]
library(plm)
library(pgmm)
install.packages("pgmm")
data(olive)
install.packages("C:/Users/Alexis/Downloads/pgmm_1.0.tar.gz", repos = NULL, type = "source")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
train <- segmentationOriginal[segmentationOriginal$Case == "Train",]
test <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
fit <- train(Class~.,method="rpart",data=train)
print(fit)
plot(fit$finalModel,uniform=TRUE)
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
data.a <- data.frame(TotalIntench2 = 23,000,
FiberWidthCh1 = 10,
PerimStatusCh1=20)
data.a
data.b <- data.frame(TotalIntench2 = 50,000,
FiberWidthCh1 = 10,
VarIntenCh4 = 100)
data.b
data.c
data.c <- data.frame(TotalIntench2 = 57,000,
FiberWidthCh1 = 8,
VarIntenCh4 = 100)
data.d <- data.frame(FiberWidthCh1 = 8,
VarIntenCh4 = 100,
PerimStatusCh1=2)
predict(fit,data.a)
predict(fit,data.b)
predict(fit,data.c)
predict(fit,data.d)
predict
predict()
fit
data.a
predict(fit, data.a)
predict(fit,data.b)
print(fit)
plot(fit$finalModel,uniform=TRUE)
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
predict(fit, data.a)
data.a
predict(fit, data.a)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(rpart)
training = segmentationOriginal[ segmentationOriginal$Case=="Train",]
testing   = segmentationOriginal[ segmentationOriginal$Case=="Test",]
set.seed(125)
modelFit <- train(training$Class ~., method="rpart", data=training)
modelFit$finalModel
print(modelFit$finalModel)
plot(modelFit$finalModel,uniform=TRUE,main="Classification Tree")
text(modelFit$finalModel,use.n=TRUE,all=TRUE,CEX=0.8)
library(rattle)
fancyRpartPlot(modelFit$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modelFit$finalModel)
library(rpart)
fancyRpartPlot(modelFit$finalModel)
install.packages("rpart.plot")
library("rpart.plot")
library(rattle)
fancyRpartPlot(modelFit$finalModel)
library(plyr)
library(ggplot)
library(ggplot2)
data(baseball)
head(baseball)
data(segmentationOriginal)
library(caret)
train <- segmentationOriginal[segmentationOriginal$Case == "Train",]
test <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
fit <- train(Class~.,method="rpart",data=train)
print(fit)
train <- segmentationOriginal[segmentationOriginal$Case == "Train", ]
test <- segmentationOriginal[segmentationOriginal$Case == "Test", ]
set.seed(125)
fit <- train(Class ~ ., method="rpart", data=train)
plot(fit$finalModel,uniform=TRUE)
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
data.a <- data.frame(TotalIntench2 = 23,000,
FiberWidthCh1 = 10,
PerimStatusCh1=20)
predict(fit, data.a)
predict(fit, data.a, newdata = test)
print(modelFit$finalModel)
fit$finalModel
print(fit$finalModel)
plot(fit$finalModel,uniform=TRUE,main="Classification Tree")
text(fit$finalModel,use.n=TRUE,all=TRUE,CEX=0.8)
fancyRpartPlot(modelFit$finalModel)
fancyRpartPlot(fit$finalModel)
data(olive)
olive = olive[,-1]
modelFit <- train(olive$Area~., method="rpart",data=olive)
data(olive)
library(pgmm)
install.packages("C:/Users/Alexis/Downloads/pgmm_1.0.tar.gz", repos = NULL, type = "source")
library(pgmm)
data(olive)
library(pgmm)
install.packages("C:/Users/Alexis/Downloads/pgmm_1.0.tar.gz", repos = NULL, type = "source")
detach(pgmm)
library(MASS)
fit1 <- glm(use~wind, family=binomial(logit),data=shuttle)
fit1
exp(fit1$coefficients)
install.pakages("rJava")
install.packages("rJava")
install.packages("XLconnect")
install.packages("XLConnect")
library(XLConnect)
library(rJava)
library(DeducerExtras)
install.packages("Deducer")
install.packages("DeducerExtra")
install.packages("DeducerExtras")
library("DeducerExtras")
JGR()
SciViewsPackages <- c("SciViews", "svMisc", "svSocket", "svGUI", "svIDE", "svKomodo", "svDialogs", "svSweave", "svTools", "svUnit", "svWidgets", "tcltk2")
install.packages(SciViewsPackages)
install.packages(SciViewsPackages)
library(svDialogs)
svGUI()
display(guiDlg("SciViews-R", "My first dialog box with SciViews-R"))
library(svDialogs)
library(svKomodo)
library(SciViewsPackages)
display(guiDlg("SciViews-R", "My first dialog box with SciViews-R"))
library(svGUI)
SciViewsPackages <- c("SciViews", "svMisc", "svSocket", "svGUI", "svIDE", "svKomodo", "svDialogs", "svSweave", "svTools", "svUnit", "svWidgets", "tcltk2")
library(SciViews)
library(svMisc)
library(svSocket)
library(svIDE)
library(svKomodo)
library(svSweave)
library(svTools)
library(svUnit)
library(svWidgets)
library(tcltk2)
display(guiDlg("SciViews-R", "My first dialog box with SciViews-R"))
help.start()
library(shiny)
shinyApp("Example_1")
shinyApp("Example1")
lapply(list(1:3, 25:29), median)
sapply(list(1:3, 25:29), median)
tapply(list(1:3, 25:29), median)
apply(list(1:3, 25:29), median)
myFirstMatrix <- matrix(1:20, 4, 5)
library(xlsReadWrite)
install.packages("xlsReadWrite")
install.packages("XLS")
write.csv(myFirstMatrix,"myFirstMatrix.csv")
setwd("C://Dropbox/5277OS - Learning Scientific Computing with R/")
myFirstMatrix <- matrix(1:20, 4, 5)
myFirstMatrix
myFirstMatrix <- matrix(1:20, nrow = 4, ncol = 5)
myFirstMatrix
myFirstMatrix <- matrix(1:20, nrow = 5, ncol = 4)
myFirstMatrix
myFirstMatrix <- matrix(1:20, 4, 5)
myFirstMatrix <- matrix(1:20, nrow = 4, ncol = 5)
myFirstMatrix <- matrix(1:20, 5, 4)
myFirstMatrix <- matrix(1:20, nrow = 5, ncol = 5)
write.csv(myFirstMatrix,"myFirstMatrix.csv")
getwd()
write.csv(myFirstMatrix,"./myFirstMatrix.csv")
myFirstMatrix <- matrix(1:20, nrow = 5, ncol = 4)
write.csv(myFirstMatrix,"./myFirstMatrix.csv")
write.csv(myFirstMatrix,"./myFirstMatrix.csv")
vector1 <- c(1:10)
vector2 <- c(101:110)
vector3 <- c(6:15)
matrix1 <- rbind(vector1, vector2, vector3)
matrix1
write.csv(matrix1,"./myFirstMatrix.csv")
write.csv(matrix1,"./matrix1.csv")
matrix2 <- cbind(vector1, vector2, vector3)
matrix2
write.csv(matrix2,"./matrix2.csv")
colnames(matrix2) <- c("column1", "column2", "column3")
rownames(matrix2) <- c(1:10)
matrix2
write.csv(matrix2,"./matrix2.csv")
matrix5 <- matrix(rep(1:10), 2, 5)
matrix5
write.csv(matrix5,"./matrix5.csv")
matrix6 <- matrix(rep(11:25), 3, 5)
matrix6
matrix7 <- rbind(matrix5, matrix6)
matrix7
write.csv(matrix6,"./matrix6.csv")
write.csv(matrix7, "./matrix7.csv")
library(gdata)
matrix2
dim(matrix2)
matrix2
matrix2
write.csv(matrix2,"./matrix2.csv")
write.csv(matrix2,"./matrix2.csv")
matrix3
matrix6
matrix 8 <- matrix6[, -5]
matrix 8 <- matrix6[, -1]
matrix 8 <- matrix6[, 1:4]
matrix 8 <- matrix6[, c(1:4)]
matrix8 <- matrix6[, -1]
matrix7 <- rbind(matrix5, matrix6)
matrix5 <- matrix(rep(1:10), 2, 5)
matrix5
matrix6 <- matrix(rep(11:25), 3, 5)
matrix6
matrix7 <- rbind(matrix5, matrix6)
matrix7
matrix8 <- matrix6[, -1]
matrix9 <- cbind(matrix5, matrix8)
matrix2[1, 1]
matrix2
matrix2[7, 3]
matrix2[1, ]
matrix2[ , 1]
matrix2[ , 1]
matrix2
matrix2[ , 3]
matrix3 <- matrix2[, -10]
matrix3
matrix3 <- matrix2[-10, ]
matrix3
write.csv(matrix3, "./matrix3.csv")
dim(matrix3)
cbindX(matrix2, matrix3)
matrix2bind3<- cbindX(matrix2, matrix3)
write.csv(matrix2bind3, "./matrix2bind3.csv")
setwd("C:/Dropbox/5277OS - Learning Scientific Computing with R/5277os")
worms <- read.table("./worms.txt", header=T)
names(worms)
worms[2, 2]
worms[2, ]
worms[order(worms$Soil.pH), ]
write.csv("worms[order(worms$Soil.pH), ]", "./wormsSoilPHOrdered.csv")
wormsSoilPHOrdered <- worms[order(worms$Soil.pH), ]
write.csv("wormsSoilPHOrdered", "./wormsSoilPHOrdered.csv")
View(wormsSoilPHOrdered)
wormsSoilPHOrdered <- as.data.frame(wormsSoilPHOrdered)
write.csv("wormsSoilPHOrdered", "./wormsSoilPHOrdered.csv")
write.csv(wormsSoilPHOrdered, "./wormsSoilPHOrdered.csv")
wormsDampTrue <- worms[Damp==T,]
wormsSoilPHOrdered <- worms[order(worms$Soil.pH), ]
wormsDampTrue <- worms[Damp==T,]
worms[-(2:10),]
na.exclude(worms)
wormsDampTrue <- worms[Damp==T, ]
wormsDampTrue <- worms[worms$Damp==T, ]
write.csv(wormsDampTrue, "./wormsDampTrue.csv")
wormsRows2To10Removed <- worms[-(2:10),]
write.csv(wormsRows2To10Removed, "./wormsRows2To10Removed.csv")
wormsNAremoved <- na.exclude(worms)
write.csv(wormsNAremoved, "./wormsNAremoved.csv")
matrix8 <- matrix(c(1:20, 41:60), nrow = 10, ncol = 2)
View(matrix8)
write.csv(matrix8, "./matrix8.csv")
apply(matrix8, 1:2, function(x) {sqrt(x) } )
write.csv((apply(matrix8, 1:2, function(x) {sqrt(x) } )), "./tmp0.csv")
myList <- list(a = 21:40, b = 31:50)
lapply(myList, sqrt)
set.seed(12)
d <- data.frame(year = rep(2000:2002, each = 3), count = round(runif(9, 0, 20)))
d <- data.frame(year = rep(2000:2002, each = 3), count = round(runif(9, 0, 20)))
print(d)
library(plyr)
ddply(d, "year", function(x) {
mean.count <- mean(x$count)
sd.count <- sd(x$count)
cv <- sd.count/mean.count
data.frame(cv.count = cv)
}
)
ddply(d, "year", summarise, mean.count = mean(count))
write.csv((ddply(d, "year", summarise, mean.count = mean(count))), "./ddplySummarize.csv"
)
ddply(d, "year", transform, total.count = sum(count))
write.csv(ddply(d, "year", transform, total.count = sum(count)), "./ddplyTransform.csv")
ddply(d, "year", mutate, mu = mean(count), sigma = sd(count), cv = sigma/mu)
write.csv((ddply(d, "year", mutate, mu = mean(count), sigma = sd(count), cv = sigma/mu)), "./ddplyMutate.csv")
ls()
write.csv(ls(), "./ddplyMutate.csv")
write.csv((ddply(d, "year", mutate, mu = mean(count), sigma = sd(count), cv = sigma/mu)), "./ddplyMutate.csv")
write.csv(ls(), "./ls_Command.csv")
save.image("C:/Dropbox/5277OS - Learning Scientific Computing with R/Code/Chapter_02/5277os_chapter2_snapshot_2014_07_07.RData")
browse.workspace()
browse.workspace
plot(worms)
worms
